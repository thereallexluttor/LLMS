{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc7efc9a5de4eeaa8b1c86ef93dc2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cb3dbbc9e74c62bc7a13239c487ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f07ed0f2a0341fba0757a138e587ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/590k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03ab7cb9f7c41719a716bb8b8fa25cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/588k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c0f343c5344fafb24ffcb8723388c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2193567b55b47e194bd18b94c562dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee34c0cdbf7b4cb3b6b13584e7db817e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a383b1004cc54190b7406da5a60c857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0dc908076140c9a432b38472d52d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0232f79337cb4bc39825e6113ab195f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/837k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11603b8b3be4465bbb85347c383a6989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad74475981ea4866b55c6362acd12320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/423k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fb7be89e5e4e39ad8d0a4b582d235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f636a3e70d4020a143026a85beb851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81433a0576db4c9891700db0d21a7967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032313d89ac94bf1a4c4915d3823a4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b8409913a4413a33eb949d2b74f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e10b68cbf44a46ab26bcd31b07b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/932k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e22b46a3f2147098e2dde2524faec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/459k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b1a2f22fa0456abf2453b8ac76a7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/464k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192d1d5e02714c64a7286f072c10d4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b9f88443840999b70046aa807fe04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d481a1cc8246c4bd33b1baddb27da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c637c2b2ed44688b31f5d8929a7bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfdb2d6cdfb47cabb8504421a64cda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469ca532c294429893d3264e710c7a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/942k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b89eac0b1c44ddab0a8d2db720f6ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/472k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a269bbe9e941c093462daf2f5c97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/472k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6925e46b68d84822a5d81a8235903d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4707671e47d34145857cf53ee41acc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf72759a9dd4463a1d147e4f4d590ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf858187898e46518eb9d3cf15616833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0008ac71b04c0db3d4bad97a18b64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516c26924a3548cab63bf0746806ee08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b130d53655c34e139107132754ec210c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acaae4fb0734a19a4da7c1caf9b6c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e13cbb45a34edb8dd37937f81792e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0271cc7c03044ae5873a468887926d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9bdf4245a411e9be15233af7076d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d20a4a21734648a56d38231ffe43b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7d446d3b55440c8daee4e49b47f236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed86d049f44484bac20c0e12385a210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1599b71d30b4677a00276b4a715f30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits,\n",
    "                                     hidden_states=outputs.hidden_states,\n",
    "                                     attentions=outputs.attentions)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9a2fdf1dce41fcabfd08ae7f2bc27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\modeling_utils.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    I-LOC  I-LOC  I-LOC  I-PER  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True,\n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True,\n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f79bd22d9484a4ba40029860d55fb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783fc6030cfd4eb7a1dec8cf6d7acfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3caf9f995594945a4de4f09d72602a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b184d41443004480830600635b84e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\modeling_utils.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "Cloning https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"],\n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181e85d7f0694cbdbd7b651de743081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2598, 'learning_rate': 3.3365079365079365e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfe32da84cf4b1aa5905f1eab0fa7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1609261929988861, 'eval_f1': 0.8229392315585452, 'eval_runtime': 257.2096, 'eval_samples_per_second': 24.455, 'eval_steps_per_second': 1.023, 'epoch': 1.0}\n",
      "{'loss': 0.1268, 'learning_rate': 1.673015873015873e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b526b9d85170480b9d93436eb913107b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13648821413516998, 'eval_f1': 0.8439082683662438, 'eval_runtime': 280.1853, 'eval_samples_per_second': 22.449, 'eval_steps_per_second': 0.939, 'epoch': 2.0}\n",
      "{'loss': 0.0813, 'learning_rate': 9.523809523809524e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b462ffcfe4646f0a24b5c8996fa52bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1375073343515396, 'eval_f1': 0.8611791512389633, 'eval_runtime': 439.6094, 'eval_samples_per_second': 14.308, 'eval_steps_per_second': 0.598, 'epoch': 3.0}\n",
      "{'train_runtime': 11311.8538, 'train_samples_per_second': 3.336, 'train_steps_per_second': 0.139, 'train_loss': 0.15582308523238653, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b68c56b316e409c9adc4847a45831e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a154651e48f24131ba7a683f1f67e75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file sentencepiece.bpe.model:   0%|          | 1.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660a8e5689ab4d5880af72988ec5d011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Nov06_13-30-45_Hedinyer/events.out.tfevents.1730896773.Hedinyer.78504.0:   0%|          | 1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185995b259114f31b9d1dcda1ed67f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15db8404cf8d47098d2b46a9acfbb4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 1.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d2c88406b54f99a0721ef88e3b502f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Nov06_13-30-45_Hedinyer/1730896773.8409648/events.out.tfevents.1730896773.Hedinyer.78504.1:  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de\n",
      "   0ba01ba..f2f29ee  main -> main\n",
      "\n",
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de\n",
      "   f2f29ee..36ea5c1  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de/commit/f2f29eea65b03a1a132523dc73862c1f1326c84f'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() \n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4     5           6    7     8        9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \n",
       "Tags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7),\n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0482cef3874db792e7ba510a16abca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.018441528, 0.0, 0.021380886, 0.0152813...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.018441528, 0.0, 0.021380886, 0.0152813...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.94</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.90</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.02           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.02           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.02           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.02           I-ORG            ▁)\n",
       "1     56530              1      O  0.00               O           ▁WE\n",
       "1     83982              1  B-ORG  0.94           B-ORG          ▁Luz\n",
       "1        10              1  I-ORG  0.90           I-PER            ▁a"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>1388</td>\n",
       "      <td>989</td>\n",
       "      <td>808</td>\n",
       "      <td>163</td>\n",
       "      <td>1171</td>\n",
       "      <td>246</td>\n",
       "      <td>2898</td>\n",
       "      <td>246</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>233.33</td>\n",
       "      <td>136.65</td>\n",
       "      <td>128.15</td>\n",
       "      <td>109.98</td>\n",
       "      <td>83.18</td>\n",
       "      <td>79.55</td>\n",
       "      <td>76.44</td>\n",
       "      <td>75.9</td>\n",
       "      <td>69.6</td>\n",
       "      <td>52.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3      4      5      6     7     8  \\\n",
       "input_tokens       ▁    ▁der     ▁in    ▁von     ▁/   ▁und     ▁(   ▁''    ▁)   \n",
       "count           6066    1388     989     808    163   1171    246  2898   246   \n",
       "mean            0.04     0.1    0.13    0.14   0.51   0.07   0.31  0.03  0.28   \n",
       "sum           233.33  136.65  128.15  109.98  83.18  79.55  76.44  75.9  69.6   \n",
       "\n",
       "                  9  \n",
       "input_tokens     ▁D  \n",
       "count            89  \n",
       "mean           0.59  \n",
       "sum           52.51  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462</td>\n",
       "      <td>2683</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1039.43</td>\n",
       "      <td>1661.08</td>\n",
       "      <td>1817.98</td>\n",
       "      <td>1077.78</td>\n",
       "      <td>781.13</td>\n",
       "      <td>693.31</td>\n",
       "      <td>1386.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2        3       4       5        6\n",
       "labels    I-LOC    B-ORG    I-ORG    B-LOC   B-PER   I-PER        O\n",
       "count      1462     2683     3820     3172    2893    4139    43648\n",
       "mean       0.71     0.62     0.48     0.34    0.27    0.17     0.03\n",
       "sum     1039.43  1661.08  1817.98  1077.78  781.13  693.31  1386.42"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.31</td>\n",
       "      <td>10.47</td>\n",
       "      <td>9.98</td>\n",
       "      <td>9.23</td>\n",
       "      <td>10.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.49</td>\n",
       "      <td>10.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9   \\\n",
       "tokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  I-ORG     O     O      O      O      O      O   \n",
       "losses  0.00  0.00   4.16   0.00  0.00  0.00  10.31  10.47   9.98   9.23   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses  10.05  0.00   9.16   9.96  0.00   9.49  10.19  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>7.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.53</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.68</td>\n",
       "      <td>6.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.35</td>\n",
       "      <td>9.33</td>\n",
       "      <td>8.04</td>\n",
       "      <td>7.08</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses   7.81  0.00  0.00   6.53   9.29   9.68      6.59  0.00   8.35   9.33   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      8.04   7.08        4.18   0.00    0.00   0.01   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>6.45</td>\n",
       "      <td>5.66</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.78</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.43</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     6.45      5.66    6.34         0.00      6.25   0.00     6.07   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      5.78   5.93   6.16      6.43      5.91       5.86   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels,\n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Ham</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2             3      4      5\n",
       "tokens   ▁Ham      a     ▁(  ▁Unternehmen     ▁)   </s>\n",
       "labels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\n",
       "preds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\n",
       "losses   0.02   0.00   0.02          0.02   0.02   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Kesk</td>\n",
       "      <td>kül</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Mart</td>\n",
       "      <td>na</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7\n",
       "tokens  ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)   </s>\n",
       "labels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.03   0.00   0.00   0.02   0.03   0.00   0.03   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526369341ed74bcbbece5e00796d6534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.865\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ▁Cali    for    nie  </s>  \n",
       "Tags    B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eece96cecebb4a748d3e4d2e2cbfbcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddf1bbb92e74e07ad00c12c24a913c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e37c0833024d48946470955c9dbdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.695\n"
     ]
    }
   ],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])\n",
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be714b0d02a40b0aca6f26dece64cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bfdc83656649fe85c2576c4bbdbb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959e255d54084eadad23de8354a850b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.663\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fffc82e7da445db96e78a421edbdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39599f6de757448f8ef622bdd34ea397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fde51428a64806a3045cf594a65dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.589\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b00937bcff64ef5a0d2b83ea8d85f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\modeling_utils.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377db539dab9415fa3c8d1966c57b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7756, 'learning_rate': 3.484848484848485e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97e92a3621941799e2947c15e2da8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2856577634811401, 'eval_f1': 0.05150214592274678, 'eval_runtime': 101.7137, 'eval_samples_per_second': 22.514, 'eval_steps_per_second': 0.944, 'epoch': 1.0}\n",
      "{'loss': 1.2405, 'learning_rate': 1.9696969696969697e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908831b492ed4464a3c6e36c33307124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1200207471847534, 'eval_f1': 0.1926243002963451, 'eval_runtime': 103.6754, 'eval_samples_per_second': 22.088, 'eval_steps_per_second': 0.926, 'epoch': 2.0}\n",
      "{'loss': 1.0449, 'learning_rate': 4.5454545454545455e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6d4d2bce21480b83aa38219fb387ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9994437098503113, 'eval_f1': 0.19164687805559438, 'eval_runtime': 102.7587, 'eval_samples_per_second': 22.285, 'eval_steps_per_second': 0.934, 'epoch': 3.0}\n",
      "{'train_runtime': 541.6288, 'train_samples_per_second': 1.385, 'train_steps_per_second': 0.061, 'train_loss': 1.3160979603276108, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a4e83cd2244758a85a385e252d7f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.179049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  f1_score\n",
       "0          250  0.179049"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# hide_output\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_samples \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m4000\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(\n\u001b[0;32m      4\u001b[0m         train_on_subset(panx_fr_encoded, num_samples), ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(\n",
    "        train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    return multi_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de-fr into local empty directory.\n",
      "c:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed53349eaee491eb42dae3cbb323a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2922, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f636ec778d4db882f2cb3b23b1df4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19523659348487854, 'eval_f1': 0.822624086186995, 'eval_runtime': 568.9064, 'eval_samples_per_second': 15.082, 'eval_steps_per_second': 0.629, 'epoch': 1.0}\n",
      "{'loss': 0.1447, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e5f5cd400a48ec9e4487ae460c2bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15966083109378815, 'eval_f1': 0.8459967667829491, 'eval_runtime': 376.2609, 'eval_samples_per_second': 22.803, 'eval_steps_per_second': 0.951, 'epoch': 2.0}\n",
      "{'loss': 0.0939, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3aa9b4f4d64a74a1a10bcb4848bd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16098791360855103, 'eval_f1': 0.8585738539898132, 'eval_runtime': 420.3221, 'eval_samples_per_second': 20.413, 'eval_steps_per_second': 0.852, 'epoch': 3.0}\n",
      "{'train_runtime': 17249.8702, 'train_samples_per_second': 2.984, 'train_steps_per_second': 0.124, 'train_loss': 0.1769377274946733, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66820295d914d3aa154a2ae47d383a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc5f1b61e3448709ce3df29d8113fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file sentencepiece.bpe.model:   0%|          | 1.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d7436c8e8f4541ace078f41f87c03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 1.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1751d45c09aa448495450b3b9756a617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de-fr\n",
      "   477ebc8..99ed5b3  main -> main\n",
      "\n",
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de-fr\n",
      "   99ed5b3..f2b81a2  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-de-fr/commit/99ed5b32a6c96ca18e4ad62aff20e0517a7984ba'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_fr_encoded[\"validation\"])\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4acaf0571549949be1053cd8177629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239d087edca54859a8c79bc759e1e0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.871\n",
      "F1-score of [de-fr] model on [fr] dataset: 0.855\n",
      "F1-score of [de-fr] model on [it] dataset: 0.792\n",
      "F1-score of [de-fr] model on [en] dataset: 0.686\n"
     ]
    }
   ],
   "source": [
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-fr into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46af21ef835a4c9fb8cb6259cabe6c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/573 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5773, 'learning_rate': 3.3420593368237346e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c128ff640a414926a18e05d1ad3c7fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3415556848049164, 'eval_f1': 0.7894824430021634, 'eval_runtime': 122.5931, 'eval_samples_per_second': 18.68, 'eval_steps_per_second': 0.783, 'epoch': 1.0}\n",
      "{'loss': 0.2554, 'learning_rate': 1.6841186736474696e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076d0a931534033aea4e72d7066cf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3024083971977234, 'eval_f1': 0.8288832913518052, 'eval_runtime': 122.2085, 'eval_samples_per_second': 18.738, 'eval_steps_per_second': 0.786, 'epoch': 2.0}\n",
      "{'loss': 0.1695, 'learning_rate': 2.617801047120419e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c30fc105394f0e9b70296b77b14abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28257298469543457, 'eval_f1': 0.8395227692824735, 'eval_runtime': 119.9651, 'eval_samples_per_second': 19.089, 'eval_steps_per_second': 0.8, 'epoch': 3.0}\n",
      "{'train_runtime': 4670.1894, 'train_samples_per_second': 2.942, 'train_steps_per_second': 0.123, 'train_loss': 0.33309192968496687, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e78af1b5f41443c9b61bc4838391ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44af8bdd46e1480baf591b0223825f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file sentencepiece.bpe.model:   0%|          | 1.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b124e900c524058b6e48f2f44465134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 1.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c82c138a53f4a75931f26014d9c318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-fr\n",
      "   31e0e2f..e8d4951  main -> main\n",
      "\n",
      "To https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-fr\n",
      "   e8d4951..120b06f  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01ef8d3c24e43e4961a2b2dbe27c59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-it into local empty directory.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "WARNING: `git lfs clone` is deprecated and will not be updated\n          with new flags from `git clone`\n\n`git clone` has been updated in upstream Git to have comparable\nspeeds to `git lfs clone`.\nCloning into '.'...\nremote: Repository not found\nfatal: repository 'https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-it/' not found\nError(s) during clone:\n`git clone` failed: exit status 128\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\repository.py:687\u001b[0m, in \u001b[0;36mRepository.clone_from\u001b[1;34m(self, repo_url, token)\u001b[0m\n\u001b[0;32m    685\u001b[0m             env\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGIT_LFS_SKIP_SMUDGE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m--> 687\u001b[0m         \u001b[43mrun_subprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 'git lfs clone' is deprecated (will display a warning in the terminal)\u001b[39;49;00m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# but we still use it as it provides a nicer UX when downloading large\u001b[39;49;00m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# files (shows progress).\u001b[39;49;00m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgit clone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_lfs_files\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgit lfs clone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m .\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# Check if the folder is the root of a git repository\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\utils\\_subprocess.py:83\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[1;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(folder)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m     84\u001b[0m     command,\n\u001b[0;32m     85\u001b[0m     stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m     86\u001b[0m     stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m     87\u001b[0m     check\u001b[38;5;241m=\u001b[39mcheck,\n\u001b[0;32m     88\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# if not utf-8, replace char by �\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     cwd\u001b[38;5;241m=\u001b[39mfolder \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetcwd(),\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     92\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['git', 'lfs', 'clone', 'https://user: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@huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-it', '.']' returned non-zero exit status 2.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fine-tune on monolingual corpus\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ds_encoded \u001b[38;5;241m=\u001b[39m encode_panx_dataset(panx_ch[lang])\n\u001b[1;32m----> 7\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Collect F1-scores in common dict\u001b[39;00m\n\u001b[0;32m      9\u001b[0m f1_scores[lang][lang] \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m, in \u001b[0;36mtrain_on_subset\u001b[1;34m(dataset, num_samples)\u001b[0m\n\u001b[0;32m      4\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m training_args\u001b[38;5;241m.\u001b[39mlogging_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_ds) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m----> 6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxlmr_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mpush_to_hub:\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\trainer.py:406\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub:\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_git_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\trainer.py:2651\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2648\u001b[0m     repo_name \u001b[38;5;241m=\u001b[39m get_full_repo_name(repo_name, token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_token)\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m \u001b[43mRepository\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2652\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m   2657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moverwrite_output_dir:\n\u001b[0;32m   2658\u001b[0m         \u001b[38;5;66;03m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:132\u001b[0m, in \u001b[0;36m_deprecate_method.<locals>._inner_deprecate_method.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     warning_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message\n\u001b[0;32m    131\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(warning_message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\repository.py:534\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[1;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuggingface_token \u001b[38;5;241m=\u001b[39m get_token()\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clone_from \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_from\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_git_repo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_dir):\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\huggingface_hub\\repository.py:727\u001b[0m, in \u001b[0;36mRepository.clone_from\u001b[1;34m(self, repo_url, token)\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(error_msg)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n",
      "\u001b[1;31mOSError\u001b[0m: WARNING: `git lfs clone` is deprecated and will not be updated\n          with new flags from `git clone`\n\n`git clone` has been updated in upstream Git to have comparable\nspeeds to `git lfs clone`.\nCloning into '.'...\nremote: Repository not found\nfatal: repository 'https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-it/' not found\nError(s) during clone:\n`git clone` failed: exit status 128\n"
     ]
    }
   ],
   "source": [
    "corpora = [panx_de_encoded]\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/HedinyerM/xlm-roberta-base-finetuned-panx-all into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca80554d692429a8461756e272ecc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m training_args\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm-roberta-base-finetuned-panx-all\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model_init\u001b[38;5;241m=\u001b[39mmodel_init, args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      4\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator, compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m      5\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mxlmr_tokenizer, train_dataset\u001b[38;5;241m=\u001b[39mcorpora_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mcorpora_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(commit_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\trainer.py:1430\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m scale_before \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m scale_after\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed:\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hedin\\anaconda3\\envs\\llm_lab\\lib\\site-packages\\transformers\\optimization.py:359\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    355\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m    360\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    361\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "    eval_dataset=corpora_encoded[\"validation\"])\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
